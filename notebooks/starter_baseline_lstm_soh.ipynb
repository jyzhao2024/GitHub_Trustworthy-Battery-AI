{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a0dbcad-2915-4669-8e1d-eb22c0fe1a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "SOH ESTIMATION - STARTER SCRIPT\n",
      "======================================================================\n",
      "PyTorch version: 1.10.2+cu113\n",
      "Device: CUDA\n",
      "Start time: 2025-11-20 08:17:09\n",
      "======================================================================\n",
      "\n",
      "Model class defined successfully\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP AND IMPORTS\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"SOH ESTIMATION - STARTER SCRIPT\")\n",
    "print(\"=\"*70)\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"Device: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")\n",
    "print(f\"Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "\n",
    "# MODEL DEFINITION\n",
    "# ============================================================================\n",
    "\n",
    "class SimpleLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    Simple LSTM model for SOH estimation\n",
    "    \n",
    "    Architecture:\n",
    "        Input → LSTM → Fully Connected → Output\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size, num_layers=1, output_size=1, dropout=0.2):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.output_size = output_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass\"\"\"\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        last_output = lstm_out[:, -1, :]\n",
    "        output = self.fc(last_output)\n",
    "        return output\n",
    "    \n",
    "    def get_model_info(self):\n",
    "        \"\"\"Return model configuration\"\"\"\n",
    "        return {\n",
    "            \"model_type\": \"SimpleLSTM\",\n",
    "            \"input_size\": self.input_size,\n",
    "            \"hidden_size\": self.hidden_size,\n",
    "            \"num_layers\": self.num_layers,\n",
    "            \"output_size\": self.output_size,\n",
    "            \"total_parameters\": sum(p.numel() for p in self.parameters())\n",
    "        }\n",
    "\n",
    "print(\"Model class defined successfully\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9f6475-14cf-480e-a684-fe4ae87c3d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully from: ../data/cycles_example.csv\n",
      "  • Data shape: (29, 7)\n",
      "  • Columns: ['cycle_number', 'time_s', 'current_A', 'voltage_v', 'capacity_ah', 'temperature', 'status']\n",
      "\n",
      "Synthetic SOH labels generated\n",
      "  • SOH range: 0.980 - 1.000\n",
      "  • Mean SOH: 0.995\n",
      "\n",
      "Features extracted\n",
      "  • Feature shape: (29, 5)\n",
      "  • Target shape: (29,)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. DATA LOADING AND PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = '../data/cycles_example.csv'\n",
    "FEATURE_COLS = ['cycle_number', 'voltage_v', 'current_A', 'temperature', 'capacity_ah']\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(DATA_PATH):\n",
    "    raise FileNotFoundError(f\"Data file not found: {DATA_PATH}\")\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"Data loaded successfully from: {DATA_PATH}\")\n",
    "print(f\"  • Data shape: {df.shape}\")\n",
    "print(f\"  • Columns: {df.columns.tolist()}\")\n",
    "print()\n",
    "\n",
    "# Generate synthetic SOH labels\n",
    "def generate_synthetic_soh(cycle_numbers, initial_capacity=1.0, degradation_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Generate synthetic SOH based on cycle number\n",
    "    Simulates linear capacity fade with noise\n",
    "    \"\"\"\n",
    "    soh_base = initial_capacity - degradation_rate * cycle_numbers\n",
    "    noise = np.random.normal(0, 0.01, size=len(cycle_numbers))\n",
    "    soh = np.clip(soh_base + noise, 0.7, 1.0)\n",
    "    return soh\n",
    "\n",
    "cycle_numbers = df['cycle_number'].values\n",
    "soh_labels = generate_synthetic_soh(cycle_numbers)\n",
    "\n",
    "print(f\"Synthetic SOH labels generated\")\n",
    "print(f\"  • SOH range: {soh_labels.min():.3f} - {soh_labels.max():.3f}\")\n",
    "print(f\"  • Mean SOH: {soh_labels.mean():.3f}\")\n",
    "print()\n",
    "\n",
    "# Extract features\n",
    "features = df[FEATURE_COLS].values\n",
    "targets = soh_labels\n",
    "\n",
    "print(f\"Features extracted\")\n",
    "print(f\"  • Feature shape: {features.shape}\")\n",
    "print(f\"  • Target shape: {targets.shape}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cd9dace-6659-4b8b-b725-2ae08ca07590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "LOADING DATA\n",
      "======================================================================\n",
      "\n",
      "Data loaded successfully from: ../data/cycles_example.csv\n",
      "  • Data shape: (29, 7)\n",
      "  • Columns: ['cycle_number', 'time_s', 'current_A', 'voltage_v', 'capacity_ah', 'temperature', 'status']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Data Preview (first 5 rows):\n",
      "----------------------------------------------------------------------\n",
      "   cycle_number  time_s  current_A  voltage_v  capacity_ah  temperature  \\\n",
      "0             1       0        0.0       2.04          0.0           25   \n",
      "1             1     300        1.1       2.18          0.2           25   \n",
      "2             1    1800        1.1       2.59          0.4           25   \n",
      "3             1    3600        1.1       3.31          0.6           25   \n",
      "4             1    7200        1.1       3.60          0.8           25   \n",
      "\n",
      "      status  \n",
      "0       rest  \n",
      "1  cc_charge  \n",
      "2  cc_charge  \n",
      "3  cc_charge  \n",
      "4  cc_charge  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load battery cycling data from the data directory\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"LOADING DATA\")\n",
    "print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "# Define file path\n",
    "data_path = '../data/cycles_example.csv'\n",
    "\n",
    "# Check if file exists\n",
    "if not os.path.exists(data_path):\n",
    "    raise FileNotFoundError(f\"Data file not found: {data_path}\")\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Data loaded successfully from: {data_path}\")\n",
    "print(f\"  • Data shape: {df.shape}\")\n",
    "print(f\"  • Columns: {df.columns.tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"Data Preview (first 5 rows):\")\n",
    "print(\"-\"*70)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e09319d8-d003-4957-aadd-934646f2ea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequences created\n",
      "  • Sequence length: 10\n",
      "  • X shape: (19, 10, 5)\n",
      "  • y shape: (19,)\n",
      "\n",
      "Dataset split completed\n",
      "  • Training set:   13 samples (70%)\n",
      "  • Validation set: 2 samples (15%)\n",
      "  • Test set:       4 samples (15%)\n",
      "\n",
      "DataLoaders created with batch size: 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. DATASET SPLITTING\n",
    "# ============================================================================\n",
    "\n",
    "def create_sequences(features, targets, seq_length):\n",
    "    \"\"\"Create sequences for time series prediction\"\"\"\n",
    "    X, y = [], []\n",
    "    for i in range(len(features) - seq_length):\n",
    "        X.append(features[i:i+seq_length])\n",
    "        y.append(targets[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Configuration\n",
    "SEQ_LENGTH = 10\n",
    "TRAIN_RATIO = 0.7\n",
    "VAL_RATIO = 0.15\n",
    "TEST_RATIO = 0.15\n",
    "\n",
    "# Create sequences\n",
    "X, y = create_sequences(features, targets, SEQ_LENGTH)\n",
    "\n",
    "print(f\"Sequences created\")\n",
    "print(f\"  • Sequence length: {SEQ_LENGTH}\")\n",
    "print(f\"  • X shape: {X.shape}\")\n",
    "print(f\"  • y shape: {y.shape}\")\n",
    "print()\n",
    "\n",
    "# Calculate split indices\n",
    "n_samples = len(X)\n",
    "train_size = int(n_samples * TRAIN_RATIO)\n",
    "val_size = int(n_samples * VAL_RATIO)\n",
    "\n",
    "# Split the data\n",
    "X_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "X_val = X[train_size:train_size+val_size]\n",
    "y_val = y[train_size:train_size+val_size]\n",
    "\n",
    "X_test = X[train_size+val_size:]\n",
    "y_test = y[train_size+val_size:]\n",
    "\n",
    "print(f\"Dataset split completed\")\n",
    "print(f\"  • Training set:   {len(X_train)} samples ({TRAIN_RATIO*100:.0f}%)\")\n",
    "print(f\"  • Validation set: {len(X_val)} samples ({VAL_RATIO*100:.0f}%)\")\n",
    "print(f\"  • Test set:       {len(X_test)} samples ({TEST_RATIO*100:.0f}%)\")\n",
    "print()\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).reshape(-1, 1)\n",
    "\n",
    "X_val_tensor = torch.FloatTensor(X_val)\n",
    "y_val_tensor = torch.FloatTensor(y_val).reshape(-1, 1)\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).reshape(-1, 1)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "print(f\"DataLoaders created with batch size: {BATCH_SIZE}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffe00e8e-e0f2-4fea-aa46-940c529dd69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL CONFIGURATION\n",
      "======================================================================\n",
      "Model type: SimpleLSTM\n",
      "Input size: 5\n",
      "Hidden size: 32\n",
      "Number of layers: 2\n",
      "Total parameters: 13,473\n",
      "Device: cuda\n",
      "\n",
      "TRAINING CONFIGURATION\n",
      "======================================================================\n",
      "Epochs: 100\n",
      "Batch size: 4\n",
      "Learning rate: 0.001\n",
      "Weight decay: 1e-05\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "TRAINING PROGRESS\n",
      "======================================================================\n",
      "Epoch    Train Loss      Val Loss        Status              \n",
      "----------------------------------------------------------------------\n",
      "1        0.792569        0.653830        ✓ Best model        \n",
      "2        0.582704        0.448541        ✓ Best model        \n",
      "3        0.381335        0.259527        ✓ Best model        \n",
      "4        0.186860        0.106529        ✓ Best model        \n",
      "5        0.072082        0.016635        ✓ Best model        \n",
      "6        0.009538        0.003355        ✓ Best model        \n",
      "10       0.007072        0.001547        ✓ Best model        \n",
      "11       0.001662        0.000040        ✓ Best model        \n",
      "15       0.002889        0.000013        ✓ Best model        \n",
      "20       0.001641        0.000049                            \n",
      "30       0.000882        0.000392                            \n",
      "35       0.001093        0.000040        Early stopping      \n",
      "\n",
      "Early stopping triggered after 35 epochs\n",
      "----------------------------------------------------------------------\n",
      "Training completed\n",
      "  • Total epochs: 35\n",
      "  • Best validation loss: 0.000013\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 4. MODEL TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "# Model hyperparameters\n",
    "INPUT_SIZE = len(FEATURE_COLS)\n",
    "HIDDEN_SIZE = 32\n",
    "NUM_LAYERS = 2\n",
    "OUTPUT_SIZE = 1\n",
    "DROPOUT = 0.2\n",
    "\n",
    "# Training hyperparameters\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 0.001\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleLSTM(\n",
    "    input_size=INPUT_SIZE,\n",
    "    hidden_size=HIDDEN_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    output_size=OUTPUT_SIZE,\n",
    "    dropout=DROPOUT\n",
    ").to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=10, verbose=False\n",
    ")\n",
    "\n",
    "# Print model information\n",
    "model_info = model.get_model_info()\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Model type: {model_info['model_type']}\")\n",
    "print(f\"Input size: {model_info['input_size']}\")\n",
    "print(f\"Hidden size: {model_info['hidden_size']}\")\n",
    "print(f\"Number of layers: {model_info['num_layers']}\")\n",
    "print(f\"Total parameters: {model_info['total_parameters']:,}\")\n",
    "print(f\"Device: {device}\")\n",
    "print()\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Weight decay: {WEIGHT_DECAY}\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "# Training functions\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    \"\"\"Train for one epoch\"\"\"\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    \"\"\"Validate the model\"\"\"\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_X, batch_y in val_loader:\n",
    "            batch_X = batch_X.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(val_loader)\n",
    "\n",
    "# Training loop\n",
    "training_history = {\n",
    "    'train_loss': [],\n",
    "    'val_loss': [],\n",
    "    'epochs': []\n",
    "}\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "early_stopping_patience = 20\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRAINING PROGRESS\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Epoch':<8} {'Train Loss':<15} {'Val Loss':<15} {'Status':<20}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    # Train\n",
    "    train_loss = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "    \n",
    "    # Validate\n",
    "    val_loss = validate(model, val_loader, criterion, device)\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    \n",
    "    # Save history\n",
    "    training_history['epochs'].append(epoch + 1)\n",
    "    training_history['train_loss'].append(train_loss)\n",
    "    training_history['val_loss'].append(val_loss)\n",
    "    \n",
    "    # Check for improvement\n",
    "    status = \"\"\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        status = \"✓ Best model\"\n",
    "        # Save best model\n",
    "        os.makedirs('../models', exist_ok=True)\n",
    "        torch.save(model.state_dict(), '../models/best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= early_stopping_patience:\n",
    "            status = \"Early stopping\"\n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0 or status:\n",
    "        print(f\"{epoch+1:<8} {train_loss:<15.6f} {val_loss:<15.6f} {status:<20}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(f\"\\nEarly stopping triggered after {epoch+1} epochs\")\n",
    "        break\n",
    "\n",
    "print(\"-\"*70)\n",
    "print(f\"Training completed\")\n",
    "print(f\"  • Total epochs: {len(training_history['epochs'])}\")\n",
    "print(f\"  • Best validation loss: {best_val_loss:.6f}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74b51c66-3dbb-443c-bcaa-b99c280503be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MODEL TESTING\n",
      "======================================================================\n",
      "Predictions completed\n",
      "  • Test samples: 4\n",
      "  • True SOH range: 0.991 - 1.000\n",
      "  • Predicted SOH range: 0.995 - 0.997\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5. MODEL TESTING AND RESULTS SAVING\n",
    "# ============================================================================\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('../models/best_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODEL TESTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Make predictions\n",
    "y_true_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        outputs = model(batch_X)\n",
    "        \n",
    "        y_true_list.extend(batch_y.cpu().numpy().flatten())\n",
    "        y_pred_list.extend(outputs.cpu().numpy().flatten())\n",
    "\n",
    "y_true = np.array(y_true_list)\n",
    "y_pred = np.array(y_pred_list)\n",
    "\n",
    "print(f\"Predictions completed\")\n",
    "print(f\"  • Test samples: {len(y_true)}\")\n",
    "print(f\"  • True SOH range: {y_true.min():.3f} - {y_true.max():.3f}\")\n",
    "print(f\"  • Predicted SOH range: {y_pred.min():.3f} - {y_pred.max():.3f}\")\n",
    "print()\n",
    "\n",
    "# Prepare test results\n",
    "test_results = {\n",
    "    \"soh_true\": (y_true * 100).tolist(),\n",
    "    \"soh_predicted\": (y_pred * 100).tolist(),\n",
    "    \"sample_indices\": list(range(len(y_true)))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8567e46f-43c7-46d8-82e1-6de143de612d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PERFORMANCE EVALUATION\n",
      "======================================================================\n",
      "\n",
      "Regression Metrics:\n",
      "  • MAE:   0.003134  (0.3134%)\n",
      "  • RMSE:  0.003417  (0.3417%)\n",
      "  • R²:    0.139523\n",
      "  • MAPE:  0.3146%\n",
      "\n",
      "Error Analysis:\n",
      "  • Max Error: 0.004947  (0.4947%)\n",
      "  • Mean Error: 0.000661\n",
      "  • Std Error: 0.003352\n",
      "\n",
      "Accuracy Metrics:\n",
      "  • Within ±3%: 100.00%\n",
      "  • Within ±5%: 100.00%\n",
      "\n",
      "Performance Assessment: Excellent performance (MAE < 2%)\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "RESULTS SAVED\n",
      "======================================================================\n",
      "Complete results: C:\\Users\\19069\\GitHub_Trustworthy Battery AI\\results\\soh_estimation_complete_results.json\n",
      "Model weights: ../models/best_model.pth\n",
      "======================================================================\n",
      "\n",
      "WORKFLOW COMPLETED SUCCESSFULLY!\n"
     ]
    }
   ],
   "source": [
    "# 6. PERFORMANCE EVALUATION AND ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calculate comprehensive evaluation metrics\"\"\"\n",
    "    y_true = np.array(y_true)\n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    errors = y_true - y_pred\n",
    "    abs_errors = np.abs(errors)\n",
    "    squared_errors = errors ** 2\n",
    "    \n",
    "    mae = np.mean(abs_errors)\n",
    "    rmse = np.sqrt(np.mean(squared_errors))\n",
    "    \n",
    "    ss_res = np.sum(squared_errors)\n",
    "    ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)\n",
    "    r2 = 1 - (ss_res / ss_tot) if ss_tot > 0 else 0\n",
    "    \n",
    "    mape = np.mean(abs_errors / (np.abs(y_true) + 1e-10)) * 100\n",
    "    max_error = np.max(abs_errors)\n",
    "    \n",
    "    accuracy_3_percent = np.mean(abs_errors < 0.03) * 100\n",
    "    accuracy_5_percent = np.mean(abs_errors < 0.05) * 100\n",
    "    \n",
    "    mean_error = np.mean(errors)\n",
    "    std_error = np.std(errors)\n",
    "    \n",
    "    return {\n",
    "        \"mae\": float(mae),\n",
    "        \"rmse\": float(rmse),\n",
    "        \"r2_score\": float(r2),\n",
    "        \"mape\": float(mape),\n",
    "        \"max_error\": float(max_error),\n",
    "        \"accuracy_within_3_percent\": float(accuracy_3_percent),\n",
    "        \"accuracy_within_5_percent\": float(accuracy_5_percent),\n",
    "        \"mean_error\": float(mean_error),\n",
    "        \"std_error\": float(std_error)\n",
    "    }\n",
    "\n",
    "# Calculate metrics\n",
    "evaluation_metrics = calculate_metrics(y_true, y_pred)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"Regression Metrics:\")\n",
    "print(f\"  • MAE:   {evaluation_metrics['mae']:.6f}  ({evaluation_metrics['mae']*100:.4f}%)\")\n",
    "print(f\"  • RMSE:  {evaluation_metrics['rmse']:.6f}  ({evaluation_metrics['rmse']*100:.4f}%)\")\n",
    "print(f\"  • R²:    {evaluation_metrics['r2_score']:.6f}\")\n",
    "print(f\"  • MAPE:  {evaluation_metrics['mape']:.4f}%\")\n",
    "print()\n",
    "print(\"Error Analysis:\")\n",
    "print(f\"  • Max Error: {evaluation_metrics['max_error']:.6f}  ({evaluation_metrics['max_error']*100:.4f}%)\")\n",
    "print(f\"  • Mean Error: {evaluation_metrics['mean_error']:.6f}\")\n",
    "print(f\"  • Std Error: {evaluation_metrics['std_error']:.6f}\")\n",
    "print()\n",
    "print(\"Accuracy Metrics:\")\n",
    "print(f\"  • Within ±3%: {evaluation_metrics['accuracy_within_3_percent']:.2f}%\")\n",
    "print(f\"  • Within ±5%: {evaluation_metrics['accuracy_within_5_percent']:.2f}%\")\n",
    "print()\n",
    "\n",
    "# Performance assessment\n",
    "mae_percent = evaluation_metrics['mae'] * 100\n",
    "if mae_percent < 2:\n",
    "    assessment = \"Excellent performance (MAE < 2%)\"\n",
    "elif mae_percent < 3:\n",
    "    assessment = \"Very good performance (MAE < 3%)\"\n",
    "elif mae_percent < 5:\n",
    "    assessment = \"Good performance (MAE < 5%)\"\n",
    "elif mae_percent < 10:\n",
    "    assessment = \"Acceptable performance (MAE < 10%)\"\n",
    "else:\n",
    "    assessment = \"Needs improvement (MAE ≥ 10%)\"\n",
    "\n",
    "print(f\"Performance Assessment: {assessment}\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# SAVE COMPLETE RESULTS\n",
    "# ============================================================================\n",
    "\n",
    "complete_results = {\n",
    "    \"model_info\": {\n",
    "        \"model_type\": model_info['model_type'],\n",
    "        \"model_version\": \"baseline_v1.0\",\n",
    "        \"architecture\": {\n",
    "            \"input_size\": model_info['input_size'],\n",
    "            \"hidden_size\": model_info['hidden_size'],\n",
    "            \"num_layers\": model_info['num_layers'],\n",
    "            \"output_size\": model_info['output_size'],\n",
    "            \"dropout\": DROPOUT\n",
    "        },\n",
    "        \"total_parameters\": model_info['total_parameters'],\n",
    "        \"input_features\": FEATURE_COLS,\n",
    "        \"sequence_length\": SEQ_LENGTH\n",
    "    },\n",
    "    \"training_configuration\": {\n",
    "        \"num_epochs\": len(training_history['epochs']),\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"weight_decay\": WEIGHT_DECAY,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_function\": \"MSE\"\n",
    "    },\n",
    "    \"training_history\": training_history,\n",
    "    \"dataset_info\": {\n",
    "        \"data_source\": DATA_PATH,\n",
    "        \"total_sequences\": n_samples,\n",
    "        \"train_samples\": len(X_train),\n",
    "        \"val_samples\": len(X_val),\n",
    "        \"test_samples\": len(X_test)\n",
    "    },\n",
    "    \"test_results\": test_results,\n",
    "    \"evaluation_metrics\": evaluation_metrics,\n",
    "    \"metadata\": {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"pytorch_version\": torch.__version__,\n",
    "        \"device\": str(device),\n",
    "        \"seed\": SEED\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save results\n",
    "results_dir = '../results'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "output_path = os.path.join(results_dir, 'soh_estimation_complete_results.json')\n",
    "\n",
    "with open(output_path, 'w') as f:\n",
    "    json.dump(complete_results, f, indent=4)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS SAVED\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Complete results: {os.path.abspath(output_path)}\")\n",
    "print(f\"Model weights: ../models/best_model.pth\")\n",
    "print(\"=\"*70)\n",
    "print()\n",
    "print(\"WORKFLOW COMPLETED SUCCESSFULLY!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbcc4b7-711f-44b3-8f83-8ee3ad924a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
